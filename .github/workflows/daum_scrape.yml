# .github/workflows/daum_scrape.yml
name: Daum News Scraper

on:
  schedule:
    - cron: '0 8 * * *'  # 매일 오전 8시 UTC (한국 시간 오후 5시)
  workflow_dispatch:  # 수동 실행 가능

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Check out repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4

    - name: Run scraper
      run: python Daum_Crawler.py

    - name: Commit and push results
      run: |
        git config --global user.name 'GitHub Action'
        git config --global user.email 'action@github.com'
        git add daum_News.json
        git commit -m "Update daum_News.json $(date)" || echo "No changes to commit"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
